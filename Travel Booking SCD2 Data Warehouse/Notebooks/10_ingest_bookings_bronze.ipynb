{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95b5a2bb-3696-497b-901d-7cbdd9cc2594",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAVEL BOOKING SCD2 MERGE PROJECT - BRONZE LAYER: BOOKING DATA INGESTION\n",
    "# =============================================================================\n",
    "# This notebook ingests booking transaction data into the bronze layer\n",
    "# Purpose: Raw data ingestion with metadata enrichment for downstream processing\n",
    "# Data Quality: Preserves original data structure with audit columns\n",
    "# Output: Creates/updates bronze.booking_inc table with daily booking transactions\n",
    "\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# =============================================================================\n",
    "# PARAMETER EXTRACTION WITH DEFAULTS\n",
    "# =============================================================================\n",
    "# Extract widget parameters with fallback defaults for flexibility\n",
    "# arrival_date: Business date for processing (defaults to today)\n",
    "# catalog: Unity Catalog name (defaults to travel_bookings)\n",
    "# schema: Target schema (defaults to default)\n",
    "# base_volume: Base path for data files (defaults to /Volumes/{catalog}/{schema}/data)\n",
    "\n",
    "import datetime as _dt\n",
    "try:\n",
    "    arrival_date = dbutils.widgets.get(\"arrival_date\")\n",
    "except Exception:\n",
    "    arrival_date = _dt.date.today().strftime(\"%Y-%m-%d\")\n",
    "try:\n",
    "    catalog = dbutils.widgets.get(\"catalog\")\n",
    "except Exception:\n",
    "    catalog = \"travel_bookings\"\n",
    "try:\n",
    "    schema = dbutils.widgets.get(\"schema\")\n",
    "except Exception:\n",
    "    schema = \"default\"\n",
    "try:\n",
    "    base_volume = dbutils.widgets.get(\"base_volume\")\n",
    "except Exception:\n",
    "    base_volume = f\"/Volumes/{catalog}/{schema}/data\"\n",
    "\n",
    "# =============================================================================\n",
    "# DATA INGESTION CONFIGURATION\n",
    "# =============================================================================\n",
    "# Construct file path and configure CSV reader for booking data\n",
    "# Handles quoted fields, multi-line records, and schema inference\n",
    "\n",
    "booking_path = f\"{base_volume}/booking_data/bookings_{arrival_date}.csv\"\n",
    "\n",
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    "      .option(\"quote\",\"\\\"\").option(\"multiLine\",\"true\")\n",
    "      .load(booking_path))\n",
    "\n",
    "# =============================================================================\n",
    "# METADATA ENRICHMENT\n",
    "# =============================================================================\n",
    "# Add audit columns for data lineage and business context\n",
    "# ingestion_time: Timestamp when data was processed\n",
    "# business_date: Business date for partitioning and filtering\n",
    "\n",
    "df = df.withColumn(\"ingestion_time\", current_timestamp()) \\\n",
    "       .withColumn(\"business_date\", F.to_date(F.lit(arrival_date)))\n",
    "\n",
    "# =============================================================================\n",
    "# BRONZE LAYER STORAGE\n",
    "# =============================================================================\n",
    "# Create bronze schema and save data to Delta table\n",
    "# Uses append mode for incremental loading\n",
    "# Delta format provides ACID properties and schema evolution\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.bronze\")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"append\").saveAsTable(f\"{catalog}.bronze.booking_inc\")\n",
    "\n",
    "print(f\"Ingested rows: {df.count()}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10_ingest_bookings_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
