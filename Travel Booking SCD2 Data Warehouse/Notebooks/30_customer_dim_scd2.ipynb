{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae60e124-4b47-4470-b811-4e6edcdadf7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAVEL BOOKING SCD2 MERGE PROJECT - SILVER LAYER: CUSTOMER DIMENSION SCD2\n",
    "# =============================================================================\n",
    "# This notebook implements SCD2 (Slowly Changing Dimension Type 2) for customer data\n",
    "# Purpose: Maintains historical versions of customer attributes with temporal tracking\n",
    "# SCD2 Logic: Closes old versions and creates new versions when attributes change\n",
    "# Output: Creates/updates customer_dim table with surrogate keys and temporal columns\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# =============================================================================\n",
    "# PARAMETER EXTRACTION WITH DEFAULTS\n",
    "# =============================================================================\n",
    "# Extract widget parameters with fallback defaults for flexibility\n",
    "# arrival_date: Business date for processing (defaults to today)\n",
    "# catalog: Unity Catalog name (defaults to travel_bookings)\n",
    "# schema: Target schema (defaults to default)\n",
    "\n",
    "import datetime as _dt\n",
    "try:\n",
    "    arrival_date = dbutils.widgets.get(\"arrival_date\")\n",
    "except Exception:\n",
    "    arrival_date = _dt.date.today().strftime(\"%Y-%m-%d\")\n",
    "try:\n",
    "    catalog = dbutils.widgets.get(\"catalog\")\n",
    "except Exception:\n",
    "    catalog = \"travel_bookings\"\n",
    "try:\n",
    "    schema = dbutils.widgets.get(\"schema\")\n",
    "except Exception:\n",
    "    schema = \"default\"\n",
    "\n",
    "# =============================================================================\n",
    "# SOURCE DATA PREPARATION\n",
    "# =============================================================================\n",
    "# Load customer data from bronze layer for the specified business date\n",
    "# Filters to current day's data for incremental processing\n",
    "\n",
    "src = spark.table(f\"{catalog}.bronze.customer_inc\").where(F.col(\"business_date\") == F.to_date(F.lit(arrival_date)))\n",
    "\n",
    "dim_full_name = f\"{catalog}.{schema}.customer_dim\"\n",
    "\n",
    "# =============================================================================\n",
    "# DIMENSION TABLE SCHEMA DEFINITION\n",
    "# =============================================================================\n",
    "# Create customer dimension table with surrogate key and SCD2 columns\n",
    "# customer_sk: Surrogate key (auto-generated identity)\n",
    "# customer_id: Natural key from source system\n",
    "# SCD2 columns: valid_from, valid_to, is_current for temporal tracking\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {dim_full_name} (\n",
    "  customer_sk BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "  customer_id INT,\n",
    "  customer_name STRING,\n",
    "  customer_address STRING,\n",
    "  email STRING,\n",
    "  valid_from DATE,\n",
    "  valid_to DATE,\n",
    "  is_current BOOLEAN\n",
    ") USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# SCD2 MERGE LOGIC\n",
    "# =============================================================================\n",
    "# Implement SCD2 pattern: close old versions and create new versions\n",
    "# Step 1: Close current rows where attributes have changed\n",
    "# Step 2: Insert new current versions for changed rows\n",
    "\n",
    "if spark.catalog.tableExists(dim_full_name):\n",
    "  dim = DeltaTable.forName(spark, dim_full_name)\n",
    "\n",
    "  # Step 1: Close current rows where attributes change\n",
    "  # Updates valid_to and is_current for existing records with changed attributes\n",
    "  (dim.alias(\"d\").merge(\n",
    "      src.alias(\"s\"),\n",
    "      \"d.customer_id = s.customer_id AND d.is_current = true\"\n",
    "    )\n",
    "    .whenMatchedUpdate(\n",
    "      condition=\"d.customer_name <> s.customer_name OR d.customer_address <> s.customer_address OR d.email <> s.email\",\n",
    "      set={\"valid_to\": \"s.valid_from\", \"is_current\": \"false\"}\n",
    "    )\n",
    "    .whenNotMatchedInsert(values={\n",
    "      \"customer_id\": \"s.customer_id\",\n",
    "      \"customer_name\": \"s.customer_name\",\n",
    "      \"customer_address\": \"s.customer_address\",\n",
    "      \"email\": \"s.email\",\n",
    "      \"valid_from\": \"s.valid_from\",\n",
    "      \"valid_to\": \"s.valid_to\",\n",
    "      \"is_current\": \"true\"\n",
    "    })\n",
    "    .execute())\n",
    "\n",
    "  # Step 2: Insert new current versions for changed rows\n",
    "  # Creates new records for customers with changed attributes\n",
    "  # Surrogate key (customer_sk) is auto-generated by IDENTITY column\n",
    "  changed = spark.sql(f\"\"\"\n",
    "    SELECT s.customer_id, s.customer_name, s.customer_address, s.email, s.valid_from, s.valid_to, true AS is_current\n",
    "    FROM {catalog}.bronze.customer_inc s\n",
    "    LEFT JOIN {dim_full_name} d\n",
    "      ON d.customer_id = s.customer_id AND d.valid_from = s.valid_from AND d.is_current = true\n",
    "    WHERE s.business_date = DATE('{arrival_date}') AND d.customer_id IS NULL\n",
    "  \"\"\")\n",
    "  if changed.count() > 0:\n",
    "    changed.write.mode(\"append\").format(\"delta\").saveAsTable(dim_full_name)\n",
    "else:\n",
    "  # =============================================================================\n",
    "  # INITIAL LOAD\n",
    "  # =============================================================================\n",
    "  # For first-time setup, load all customer data as current versions\n",
    "  # Surrogate keys will be auto-generated during initial load\n",
    "  \n",
    "  init = src.select(\"customer_id\",\"customer_name\",\"customer_address\",\"email\",\"valid_from\",\"valid_to\",\"is_current\")\n",
    "  init.write.mode(\"append\").format(\"delta\").saveAsTable(dim_full_name)\n",
    "\n",
    "print(\"SCD2 (dimension) merge complete\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "30_customer_dim_scd2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
